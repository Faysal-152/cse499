{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of MS with Normalization_Oversampling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1tVrSYqKNa6cVjN8my34mj7UuyZxwYH6u",
      "authorship_tag": "ABX9TyOlDTSm6+iaL38BADA29jUd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Faysal-152/cse499/blob/main/Copy_of_MS_with_Normalization_Oversampling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qd9LJlU6FcNR"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shd2IZpIF4Xr"
      },
      "source": [
        "df= pd.read_csv(\"/content/drive/MyDrive/dataset/MS-Final_DRAFT.csv\",encoding=\"cp1252\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNdOtEIvF4ak"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRQw5bVWF4db"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMf6kZ7IF4fz"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBhnIqy3F4iM"
      },
      "source": [
        "ax = df['University Class'].value_counts().plot(kind='bar',\n",
        "                                    figsize=(14,8),\n",
        "                                    title=\"Number of Candidates in each Class\")\n",
        "ax.set_xlabel(\"Class Name\")\n",
        "ax.set_ylabel(\"Number\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NqSxCVqMtAn"
      },
      "source": [
        "df['University Class'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MlBMUkuF4kn"
      },
      "source": [
        "ax = df['Undergrade University'].value_counts().plot(kind='bar',\n",
        "                                    figsize=(14,8),\n",
        "                                    title=\"Number of accepted candidates from each top University of bangladesh\")\n",
        "ax.set_xlabel(\"University Name\")\n",
        "ax.set_ylabel(\"Number\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrTeCgxqF4nP"
      },
      "source": [
        "ax = df['Undergrade Department'].value_counts().plot(kind='bar',\n",
        "                                    figsize=(14,8),\n",
        "                                    title=\"Number of accepted candidates from different Subject\")\n",
        "ax.set_xlabel(\"Subject Name\")\n",
        "ax.set_ylabel(\"Number\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92Z0b1kPJLqs"
      },
      "source": [
        "Relplotting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rovsbSp6I-bU"
      },
      "source": [
        "sns.relplot(data=df, x=\"Undergrade CGPA\", y=\"IELTS/TOEFL\", hue=\"University Class\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8688AyKmI-ds"
      },
      "source": [
        "sns.relplot(data=df, x=\"Undergrade CGPA\", y=\"GRE\", hue=\"University Class\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZJQQ49cI-h8"
      },
      "source": [
        "sns.relplot(data=df, x=\"Undergrade CGPA\", y=\"Conference Paper\", hue=\"University Class\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxXJTq_0I-kV"
      },
      "source": [
        "sns.relplot(data=df, x=\"Undergrade CGPA\", y=\"Journal Paper\", hue=\"University Class\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNqbCJLrI-pN"
      },
      "source": [
        "sns.relplot(data=df, x=\"Undergrade CGPA\", y=\"IELTS/TOEFL\", hue=\"University Class\", col=\"University Class\", col_wrap=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ot2cL71LAKW"
      },
      "source": [
        "sns.relplot(data=df, x=\"Undergrade CGPA\", y=\"GRE\", hue=\"University Class\", col=\"University Class\", col_wrap=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAPmSup-LAM9"
      },
      "source": [
        "sns.relplot(data=df, x=\"Undergrade CGPA\", y=\"Conference Paper\", hue=\"University Class\", col=\"University Class\", col_wrap=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGo0eyIGLAPV"
      },
      "source": [
        "sns.relplot(data=df, x=\"Undergrade CGPA\", y=\"Journal Paper\", hue=\"University Class\", col=\"University Class\", col_wrap=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iElPC6GdNFj9"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsHeiSKGMS3d"
      },
      "source": [
        "Regression Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrXFzWO6L9Ov"
      },
      "source": [
        "df_gre = df[df[\"GRE\"]>1 ]\n",
        "sns.regplot(data=df_gre, x=\"Undergrade CGPA\", y=\"GRE\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taXfKUhCL9RG"
      },
      "source": [
        "df_gre = df[df[\"IELTS/TOEFL\"]>1 ]\n",
        "sns.regplot(data=df_gre, x=\"Undergrade CGPA\", y=\"IELTS/TOEFL\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVmQfSiQL9TR"
      },
      "source": [
        "ax = sns.regplot(x=\"Undergrade CGPA\", y=\"IELTS/TOEFL\", data=df,\n",
        "                 x_estimator=np.mean, logx=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKsQlnZnL9Vk"
      },
      "source": [
        "sns.pairplot(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Q14PFESL9X2"
      },
      "source": [
        "sns.heatmap(df.corr(), annot = True, fmt = '.3f',\n",
        "           cmap = 'viridis', center = 0)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94c45gLYTKeW"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler() # default=(0, 1)\n",
        "numerical = ['Undergrade CGPA',\n",
        "             'IELTS/TOEFL','GRE',\n",
        "             'Conference Paper','Journal Paper']\n",
        "\n",
        "features_tf = pd.DataFrame(data=df)\n",
        "features_tf[numerical] = scaler.fit_transform(features_tf[numerical])\n",
        "features_tf.head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0F7VaJVQMbW"
      },
      "source": [
        "data = features_tf.iloc[:,1:].values\n",
        "labels = features_tf['University Class']\n",
        "features_tf = features_tf.drop(columns=['University Class'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSLr0STWeZHG"
      },
      "source": [
        "labels.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DXxDWxzQMeA"
      },
      "source": [
        "data1 = pd.get_dummies(data = features_tf)\n",
        "data1.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcBaTlyhfrAU"
      },
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "oversampling = SMOTE(random_state = 123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xN7XLCNqfuQV"
      },
      "source": [
        "X_over, y_over = oversampling.fit_resample(data1,labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOO3l6Thfznl"
      },
      "source": [
        "X_over = pd.DataFrame(X_over, columns=data1.columns)\n",
        "y_over = pd.DataFrame(y_over)\n",
        "y_over.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3JeyQ6if9C0"
      },
      "source": [
        "sns.barplot(x=[\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\"], y=y_over.value_counts(normalize=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5P_vlMbQMjO"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X_over,y_over, shuffle=True, train_size = 0.75)\n",
        "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWRJC0qgjBIT"
      },
      "source": [
        "Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5QwjVxqQMpW"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "model =RandomForestClassifier()\n",
        "model.fit(x_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFsfMz4WL9bY"
      },
      "source": [
        "preds = model.predict(x_train)\n",
        "print(preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ztr7sr7LL9c0"
      },
      "source": [
        "print('F1-score% =', f1_score(y_train, preds, average='macro')*100, '|', 'Accuracy% =', accuracy_score(y_train, preds)*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_emFybqRIJ2"
      },
      "source": [
        "from sklearn.metrics import plot_confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_train, preds, labels=df['University Class'].unique())\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "plot_confusion_matrix(model, x_train, y_train, normalize='true', cmap=plt.cm.Blues, ax=ax)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5oIXiw_W_cP"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "#Get the confusion matrix\n",
        "cf_matrix = confusion_matrix(y_train,preds)\n",
        "print(cf_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dq_sKj3aXYs1"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.heatmap(cf_matrix, annot=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fO88bDEGXume"
      },
      "source": [
        "make_confusion_matrix(cf_matrix, figsize=(8,6), cbar=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLNBxxDhXurE"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def make_confusion_matrix(cf,\n",
        "                          group_names=None,\n",
        "                          categories='auto',\n",
        "                          count=True,\n",
        "                          percent=True,\n",
        "                          cbar=True,\n",
        "                          xyticks=True,\n",
        "                          xyplotlabels=True,\n",
        "                          sum_stats=True,\n",
        "                          figsize=None,\n",
        "                          cmap='Blues',\n",
        "                          title=None):\n",
        "  \n",
        "\n",
        "    # CODE TO GENERATE TEXT INSIDE EACH SQUARE\n",
        "    blanks = ['' for i in range(cf.size)]\n",
        "\n",
        "    if group_names and len(group_names)==cf.size:\n",
        "        group_labels = [\"{}\\n\".format(value) for value in group_names]\n",
        "    else:\n",
        "        group_labels = blanks\n",
        "\n",
        "    if count:\n",
        "        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n",
        "    else:\n",
        "        group_counts = blanks\n",
        "\n",
        "    if percent:\n",
        "        group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten()/np.sum(cf)]\n",
        "    else:\n",
        "        group_percentages = blanks\n",
        "\n",
        "    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]\n",
        "    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n",
        "\n",
        "\n",
        "    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS\n",
        "    if sum_stats:\n",
        "        #Accuracy is sum of diagonal divided by total observations\n",
        "        accuracy  = np.trace(cf) / float(np.sum(cf))\n",
        "\n",
        "        #if it is a binary confusion matrix, show some more stats\n",
        "        if len(cf)==2:\n",
        "            #Metrics for Binary Confusion Matrices\n",
        "            precision = cf[1,1] / sum(cf[:,1])\n",
        "            recall    = cf[1,1] / sum(cf[1,:])\n",
        "            f1_score  = 2*precision*recall / (precision + recall)\n",
        "            stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(\n",
        "                accuracy,precision,recall,f1_score)\n",
        "        else:\n",
        "            stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\n",
        "    else:\n",
        "        stats_text = \"\"\n",
        "\n",
        "\n",
        "    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS\n",
        "    if figsize==None:\n",
        "        #Get default figure size if not set\n",
        "        figsize = plt.rcParams.get('figure.figsize')\n",
        "\n",
        "    if xyticks==False:\n",
        "        #Do not show categories if xyticks is False\n",
        "        categories=False\n",
        "\n",
        "\n",
        "    # MAKE THE HEATMAP VISUALIZATION\n",
        "    plt.figure(figsize=figsize)\n",
        "    sns.heatmap(cf,annot=box_labels,fmt=\"\",cmap=cmap,cbar=cbar,xticklabels=categories,yticklabels=categories)\n",
        "\n",
        "    if xyplotlabels:\n",
        "        plt.ylabel('True label')\n",
        "        plt.xlabel('Predicted label' + stats_text)\n",
        "    else:\n",
        "        plt.xlabel(stats_text)\n",
        "    \n",
        "    if title:\n",
        "        plt.title(title)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T28bGsaVjHdn"
      },
      "source": [
        "# LGBM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrvN1-F3jKBD"
      },
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "lgbmc = LGBMClassifier()\n",
        "lgbmc.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQo6w98_jKLa"
      },
      "source": [
        "preds =lgbmc.predict(x_train)\n",
        "print(preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qVjL9OUjKOX"
      },
      "source": [
        "print('F1-score% =', f1_score(y_train, preds, average='macro')*100, '|', 'Accuracy% =', accuracy_score(y_train, preds)*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnG8rXaAomsi"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_train,preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KObDXP9OjKSG"
      },
      "source": [
        "from sklearn.metrics import plot_confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_train, preds, labels=df['University Class'].unique())\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "plot_confusion_matrix(model, x_train, y_train, normalize='true', cmap=plt.cm.Blues, ax=ax)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCYmAEDajKVw"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "#Get the confusion matrix\n",
        "cf_matrix = confusion_matrix(y_train,preds)\n",
        "print(cf_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fT1_ZUlWjgRF"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.heatmap(cf_matrix, annot=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}